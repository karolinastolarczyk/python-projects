{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praca domowa \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karolina Stolarczyk 277053 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wprowadzenie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Celem poniższej pracy domowej było pobranie danych dotyczących podróży, nastepnie przygotowanie na podstawie tych danych 5 zapytań *sql*. Mieliśmy to wykonać za pomoca funkcji *read_sql_query* oraz za pomocą *zwykłych* funkcji dostepnych w bibliotece *pandas*. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wykonanie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do wykonania tego zadanie potrzebne były poniższe biblioteki:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "import sqlite3\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import timeit\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnym krokiem było wczytanie pobranych danych oraz połączenie z bazą."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tags = pd.read_csv(\"D:/Studia/Python/Tags.csv.gz\",compression = 'gzip')\n",
    "Comments = pd.read_csv(\"D:/Studia/Python/Comments.csv.gz\",compression = 'gzip')\n",
    "PostLinks = pd.read_csv(\"D:/Studia/Python/PostLinks.csv.gz\",compression = 'gzip')\n",
    "Posts = pd.read_csv(\"D:/Studia/Python/Posts.csv.gz\",compression = 'gzip')\n",
    "Users = pd.read_csv(\"D:/Studia/Python/Users.csv.gz\",compression = 'gzip')\n",
    "Votes = pd.read_csv(\"D:/Studia/Python/Votes.csv.gz\",compression = 'gzip')\n",
    "Badges = pd.read_csv(\"D:/Studia/Python/Badges.csv.gz\",compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sciezka dostepu do bazy danych:\n",
    "baza = os.path.join(tempfile.mkdtemp(), 'pd_2.db')\n",
    "if os.path.isfile(baza): # jesli baza juz istneje...\n",
    "    os.remove(baza) # ...usuniemy ja\n",
    "conn = sqlite3.connect(baza) # połaczenie do bazy danych\n",
    "\n",
    "Badges.to_sql(\"Badges\", conn) # importujemy ramke danych do bazy danych\n",
    "Comments.to_sql(\"Comments\", conn)\n",
    "PostLinks.to_sql(\"PostLinks\", conn)\n",
    "Posts.to_sql(\"Posts\", conn)\n",
    "Tags.to_sql(\"Tags\", conn)\n",
    "Users.to_sql(\"Users\", conn)\n",
    "Votes.to_sql(\"Votes\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierwsze polecenie *sql* wybiera tytuły z liczbą wpisów na ich temat oraz porządkuje je malejąco w zależności od liczby wpisów. Dane do tego zapytania pochodzą z *PostLinks* i *Posts*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie zapytania za pomoca funkcji *pd.read_sql_query* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "starttime = timeit.default_timer()\n",
    "\n",
    "df1 = pd.read_sql_query(\"\"\"\n",
    "    SELECT Posts.Title, RelatedTab.NumLinks\n",
    "    FROM\n",
    "    (SELECT RelatedPostId AS PostId, COUNT(*) AS NumLinks\n",
    "        FROM PostLinks\n",
    "        GROUP BY RelatedPostId) AS RelatedTab\n",
    "    JOIN Posts ON RelatedTab.PostId=Posts.Id\n",
    "    WHERE Posts.PostTypeId=1\n",
    "    ORDER BY NumLinks DESC\n",
    "\"\"\", conn)\n",
    "\n",
    "czas_df1 = timeit.default_timer() - starttime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykonanie zadanie za pomocą funkcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "starttime = timeit.default_timer()\n",
    "\n",
    "#Wyznaczenie tabeli RelatedTab\n",
    "RelatedTab = (PostLinks.groupby(by=['RelatedPostId'])[['RelatedPostId']].\n",
    "              aggregate(['count']).reset_index(level='RelatedPostId'))\n",
    "\n",
    "#Zmiana nazw kolumn\n",
    "RelatedTab.columns = ['PostId', 'NumLinks']\n",
    "\n",
    "#Zjoinowanie tabeli RelatedTab z tabelą Posts\n",
    "Merged = pd.merge(RelatedTab, Posts[Posts.PostTypeId == 1], how='inner', left_on='PostId', right_on='Id')\n",
    "\n",
    "#Wybranie odpowiednich kolumn i posortowanie wierszy, otrzymujemy Result - tabele końcową\n",
    "Result = Merged[['Title','NumLinks']].sort_values('NumLinks', ascending= False).reset_index(drop=True)\n",
    "\n",
    "czas_Result = timeit.default_timer() - starttime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porównanie zawartości otrzymanych wyników. Nie chcemy, żeby permutacje wierszy miały wpływ podczas porównania, dlatego zresetujemy indeksy i posortujemy je od nowa, według takiego samego porządku. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_sorted = df1.sort_values(['NumLinks','Title'], ascending= False).reset_index(drop=True)\n",
    "\n",
    "Result_sorted = Result.sort_values(['NumLinks','Title'], ascending= False).reset_index(drop=True)\n",
    "\n",
    "df1_sorted.equals(Result_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otrzymaliśmy $True$, zatem otrzymane wyniki są równoważne. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz porównajmy czas  trwania tych zapytań. \n",
    "\n",
    "Otrzymane czasy mamy poniżej. Widzimy, że czas wykonania za pomoca funkcji * pd.read_sql_query* jest około 4 razy dłuższy, niż drugim sposobem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2039264000050025, 0.059033800003817305]"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[czas_df1, czas_Result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drugie polecenie *sql* wybiera informacje o dziesięciu użytkowanikach, którzy polubili najwiekszą liczbę postów.  Wybrane informacje o tych użytkownikach to nazwa, wiek, lokalizacja, liczba polubień, najbardziej lubiany post i liczba jego polubień. Brane pod uwage były tylko posty będace pytaniami. Dane do tego zapytania pochodzą z *Posts*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie zapytania za pomoca funkcji *pd.read_sql_query* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = timeit.default_timer()\n",
    "\n",
    "df2 = pd.read_sql_query(\"\"\"\n",
    "    SELECT\n",
    "        Users.DisplayName,\n",
    "        Users.Age,\n",
    "        Users.Location,\n",
    "        SUM(Posts.FavoriteCount) AS FavoriteTotal,\n",
    "        Posts.Title AS MostFavoriteQuestion,\n",
    "        MAX(Posts.FavoriteCount) AS MostFavoriteQuestionLikes\n",
    "    FROM Posts\n",
    "    JOIN Users ON Users.Id=Posts.OwnerUserId\n",
    "    WHERE Posts.PostTypeId=1\n",
    "    GROUP BY OwnerUserId\n",
    "    ORDER BY FavoriteTotal DESC\n",
    "    LIMIT 10\n",
    "\"\"\", conn)\n",
    "\n",
    "czas_df2 = timeit.default_timer() - starttime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykonanie zadanie za pomocą funkcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = timeit.default_timer()\n",
    "\n",
    "#Utworzenie tabeli Posts2 zawierającej okreslone wiersze\n",
    "Posts2 = Posts[Posts.PostTypeId ==1 & Posts.FavoriteCount.notnull()]\n",
    "\n",
    "#Wyznaczenie tabelki z wartosciami sum i max FavoriteCount\n",
    "SumMax = (Posts2.groupby(by=['OwnerUserId'],as_index=True)[['FavoriteCount']].\n",
    "          aggregate(['sum','max']).reset_index(level='OwnerUserId'))\n",
    "          \n",
    "#Zamiana nazw kolumn         \n",
    "SumMax.columns = ['OwnerUserId','FavoriteTotal', 'MostFavoriteQuestionLikes']\n",
    "          \n",
    "#Wyznaczenie tabelki powstałej z połączenia dwóch powyzszych\n",
    "Posts3 = (pd.merge( SumMax, Posts2, how='left', left_on=['OwnerUserId','MostFavoriteQuestionLikes'], \n",
    "        right_on=['OwnerUserId','FavoriteCount'])[['OwnerUserId','FavoriteTotal','MostFavoriteQuestionLikes','Title']])\n",
    "\n",
    "#Zamiana nazw kolumn\n",
    "Posts3.columns = ['OwnerUserId','FavoriteTotal', 'MostFavoriteQuestionLikes','MostFavoriteQuestion']\n",
    "\n",
    ".x\n",
    "Merged = pd.merge(Posts3, Users[[\"DisplayName\",\"Age\",\"Location\",\"Id\"]], how='left', \n",
    "                  left_on='OwnerUserId', right_on='Id')\n",
    "\n",
    "#Wybranie kolumn i uporzadkowanie ich\n",
    "Result = (Merged[[\"DisplayName\",\"Age\", \"Location\", \"FavoriteTotal\", \"MostFavoriteQuestion\", \n",
    "                  \"MostFavoriteQuestionLikes\"]].sort_values('FavoriteTotal', ascending= False)[0:10])\n",
    "          \n",
    "czas_Result = timeit.default_timer() - starttime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porównanie zawartości otrzymanych wyników. Nie chcemy, żeby permutacje wierszy miały wpływ podczas porównania, dlatego zresetujemy indeksy i posortujemy je od nowa, według takiego samego porządku. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_sorted = df2.sort_values([\n",
    "    \"DisplayName\",\"Age\", \"Location\", \"FavoriteTotal\", \"MostFavoriteQuestion\", \"MostFavoriteQuestionLikes\"], \n",
    "    ascending= False).reset_index(drop=True)\n",
    "\n",
    "Result_sorted = Result.sort_values([\n",
    "    \"DisplayName\",\"Age\", \"Location\", \"FavoriteTotal\", \"MostFavoriteQuestion\", \"MostFavoriteQuestionLikes\"], \n",
    "    ascending= False).reset_index(drop=True)\n",
    "\n",
    "df2_sorted.equals(Result_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otrzymaliśmy $True$, zatem otrzymane wyniki są równoważne. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teraz porównajmy czas  trwania tych zapytań. \n",
    "\n",
    "Otrzymane czasy mamy poniżej. Widzimy, że czas wykonania za pomoca funkcji * pd.read_sql_query* jest około 3 razy dłuższy, niż drugim sposobem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3418999999994412, 0.09591380000347272]"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[czas_df2, czas_Result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trzecie polecenie *sql* wybiera informacje o dziesięciu najbardziej komentowanych postach oraz liczbę tych komantarzy.  Brane pod uwage były tylko posty będace pytaniami. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie zapytania za pomoca funkcji *pd.read_sql_query* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = timeit.default_timer()\n",
    "\n",
    "df3 = pd.read_sql_query(\"\"\"\n",
    "    SELECT\n",
    "        Posts.Title,\n",
    "        CmtTotScr.CommentsTotalScore\n",
    "        FROM \n",
    "        (\n",
    "        SELECT\n",
    "            PostID,\n",
    "            UserID,\n",
    "            SUM(Score) AS CommentsTotalScore\n",
    "        FROM Comments\n",
    "        GROUP BY PostID, UserID\n",
    "        ) AS CmtTotScr\n",
    "    JOIN Posts ON Posts.ID=CmtTotScr.PostID AND Posts.OwnerUserId=CmtTotScr.UserID\n",
    "    WHERE Posts.PostTypeId=1\n",
    "    ORDER BY CmtTotScr.CommentsTotalScore DESC\n",
    "    LIMIT 10\n",
    "\"\"\", conn)\n",
    "\n",
    "czas_df3 = timeit.default_timer() - starttime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykonanie zadanie za pomocą funkcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = timeit.default_timer()\n",
    "\n",
    "#Stworzenie tabelki CmtTotScr\n",
    "CmtTotScr = (Comments.groupby(by=['PostId', 'UserId'],as_index=True)[['Score']].\n",
    "             aggregate(['sum']).reset_index(level=['PostId', 'UserId']))\n",
    "\n",
    "#Zamiana kolumn\n",
    "CmtTotScr.columns = ['PostId', 'UserId','CommentsTotalScore']\n",
    "\n",
    "#Utworzenie pomocniczej tabelki Posts2\n",
    "Posts2 = Posts[Posts.PostTypeId == 1]\n",
    "\n",
    "#Połączenie dwóch powyższych tabelek\n",
    "Posts3 = pd.merge( CmtTotScr, Posts2, how='inner', left_on=['PostId','UserId'], right_on=['Id','OwnerUserId'])\n",
    "\n",
    "#Uporzadkowanie i wybranie odpowiednich kolumn\n",
    "Result = (Posts3[['Title', 'CommentsTotalScore']].\n",
    "          sort_values('CommentsTotalScore', ascending= False)[0:10].reset_index(drop=True))\n",
    "\n",
    "czas_Result = timeit.default_timer() - starttime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porównanie zawartości otrzymanych wyników. Nie chcemy, żeby permutacje wierszy miały wpływ podczas porównania, dlatego zresetujemy indeksy i posortujemy je od nowa, według takiego samego porządku. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_sorted = df3.sort_values(['CommentsTotalScore','Title'], ascending= False).reset_index(drop=True)\n",
    "\n",
    "Result_sorted = Result.sort_values(['CommentsTotalScore','Title'], ascending= False).reset_index(drop=True)\n",
    "\n",
    "df3_sorted.equals(Result_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otrzymaliśmy $True$, zatem otrzymane wyniki są równoważne. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz porównajmy czas  trwania tych zapytań. \n",
    "\n",
    "Otrzymane czasy mamy poniżej. Widzimy, że czas wykonania za pomoca funkcji * pd.read_sql_query* jest około 3 razy dłuższy, niż drugim sposobem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7614568999997573, 0.23944990000018151]"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[czas_df3, czas_Result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czwarte zapytanie *sql* wybiera niezdublowane informacje na temat użytkowników. Jest to, numer id, nazwa, reputacja, wiek i lokalizacja, którzy otrzymali przyznaną $Klasę =  1$ od 2 do 10 razy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie zapytania za pomoca funkcji *pd.read_sql_query* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = timeit.default_timer()\n",
    "\n",
    "df4 = pd.read_sql_query(\"\"\"\n",
    "    SELECT DISTINCT\n",
    "        Users.Id,\n",
    "        Users.DisplayName,\n",
    "        Users.Reputation,\n",
    "        Users.Age,\n",
    "        Users.Location\n",
    "    FROM (\n",
    "        SELECT\n",
    "            Name, UserID\n",
    "        FROM Badges\n",
    "        WHERE Name IN (\n",
    "                        SELECT\n",
    "                        Name\n",
    "                        FROM Badges\n",
    "                        WHERE Class=1\n",
    "                        GROUP BY Name\n",
    "                        HAVING COUNT(*) BETWEEN 2 AND 10\n",
    "                        )\n",
    "        AND Class=1\n",
    "        ) AS ValuableBadges\n",
    "    JOIN Users ON ValuableBadges.UserId=Users.Id\n",
    "\"\"\", conn)\n",
    "\n",
    "czas_df4 = timeit.default_timer() - starttime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykonanie zadanie za pomocą funkcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = timeit.default_timer()\n",
    "#Stworzenie tabelki BadgesName\n",
    "BadgesName = Badges[Badges.Class==1 ].groupby(by='Name')[['Name']].aggregate(['count']).reset_index(level='Name')\n",
    "\n",
    "#Zamiana nazw kolumn\n",
    "BadgesName.columns = ['Name', 'Count']\n",
    "\n",
    "#Wybranie wierszy zgodnie z założeniami\n",
    "BadgesName = BadgesName[(BadgesName.Count<10) & (BadgesName.Count>1)]\n",
    "\n",
    "#Stworzenie tabelki ValuableBadges\n",
    "ValuableBadges = pd.merge( Badges[Badges.Class==1], BadgesName, how='inner', left_on=['Name'], right_on=['Name'])\n",
    "\n",
    "#Utworzenie tabelki wynikowej, wybranie kolumn i uporzadkowanie wierszy\n",
    "Result = pd.merge( ValuableBadges, Users, how='inner', left_on=['UserId'], right_on=['Id'])[[\n",
    "            'Id_y','DisplayName','Reputation','Age','Location']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "#Poprawienie nazwy kolumny\n",
    "Result = Result.rename(columns={'Id_y':'Id'})\n",
    "\n",
    "czas_Result = timeit.default_timer() - starttime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porównanie zawartości otrzymanych wyników. Nie chcemy, żeby permutacje wierszy miały wpływ podczas porównania, dlatego zresetujemy indeksy i posortujemy je od nowa, według takiego samego porządku. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4_sorted = (df4.sort_values(['Id','DisplayName','Reputation','Age','Location'], ascending= False).\n",
    "              reset_index(drop=True))\n",
    "\n",
    "Result_sorted = (Result.sort_values(['Id','DisplayName','Reputation','Age','Location'], ascending= False).\n",
    "                 reset_index(drop=True))\n",
    "\n",
    "df4_sorted.equals(Result_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otrzymaliśmy $True$, zatem otrzymane wyniki są równoważne. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz porównajmy czas  trwania tych zapytań. \n",
    "\n",
    "Otrzymane czasy mamy poniżej. Widzimy, że czas wykonania za pomoca funkcji * pd.read_sql_query* jest około 8 razy dłuższy, niż drugim sposobem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.32294589999946766, 0.045879500001319684]"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[czas_df4, czas_Result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Piąte zapytanie *sql* wybiera tytuły postów wraz z indeksami oraz liczbę punktów za najlepszą odpowiedź, odpowiedź do zaakceptowania, a także różnicę w punktach dotyczącą tych odpowiedzi. Wyniki są uszeregowane malejąco. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytanie zapytania za pomoca funkcji *pd.read_sql_query* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = timeit.default_timer()\n",
    "\n",
    "df5 = pd.read_sql_query(\"\"\"\n",
    "    SELECT\n",
    "        Questions.Id,\n",
    "        Questions.Title,\n",
    "        BestAnswers.MaxScore,\n",
    "        Posts.Score AS AcceptedScore,\n",
    "        BestAnswers.MaxScore-Posts.Score AS Difference\n",
    "    FROM (\n",
    "        SELECT Id, ParentId, MAX(Score) AS MaxScore\n",
    "        FROM Posts\n",
    "        WHERE PostTypeId==2\n",
    "        GROUP BY ParentId\n",
    "        ) AS BestAnswers\n",
    "    JOIN (\n",
    "        SELECT * FROM Posts\n",
    "        WHERE PostTypeId==1\n",
    "        ) AS Questions\n",
    "    ON Questions.Id=BestAnswers.ParentId\n",
    "    JOIN Posts ON Questions.AcceptedAnswerId=Posts.Id\n",
    "    WHERE Difference>50\n",
    "    ORDER BY Difference DESC\n",
    "\"\"\", conn)\n",
    "\n",
    "czas_df5 = timeit.default_timer() - starttime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykonanie zadanie za pomocą funkcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "starttime = timeit.default_timer()\n",
    "\n",
    "# Tworzymy tabelkę pomocniczą z wybranymi kolumnami i o PostTypeId==2\n",
    "PostsAns = Posts[Posts.PostTypeId==2][['ParentId','Id','Score']]\n",
    "\n",
    "#Grupujemy ją by otrzymac tabelkę  BestAnswers\n",
    "BestAnswers = (PostsAns.groupby(by=['ParentId']).aggregate({'Id':['first'],'Score':['max']}).\n",
    "               reset_index(level='ParentId'))\n",
    "\n",
    "#Poprawiamy nazwy kolumn\n",
    "BestAnswers.columns = ['ParentId','Id','MaxScore']\n",
    "\n",
    "#Tworzymy tabelkę po zjoinowaniu BestAnswers i Questions\n",
    "BestQuestions = (pd.merge( BestAnswers, Posts[Posts.PostTypeId==1][['Id','Title','AcceptedAnswerId']], \n",
    "                          how='inner', left_on=['ParentId'], right_on=['Id']))\n",
    "\n",
    "#Poprawiamy nazwę kolumny\n",
    "BestQuestions = BestQuestions.rename(columns={'Id_x':'Id'})\n",
    "\n",
    "#Do poprzedniej tabelki dojoinowujemy Posts\n",
    "BestQuestionsPosts = (pd.merge(BestQuestions, Posts[['Id','Score']], how='inner', \n",
    "                               left_on=['AcceptedAnswerId'], right_on=['Id']))\n",
    "\n",
    "#Dodajemy kolumne Difference\n",
    "BestQuestionsPosts['Difference'] = BestQuestionsPosts['MaxScore'] - BestQuestionsPosts['Score']\n",
    "\n",
    "#Znowu poprawiamy nazwy kolumn\n",
    "BestQuestionsPosts = BestQuestionsPosts.rename(columns={'Id_x':'Id','Score':'AcceptedScore'})\n",
    "\n",
    "#wybieramy te z Difference> 50, desc i zmieniamy indeksowanie\n",
    "Result = (BestQuestionsPosts[BestQuestionsPosts.Difference >50].s\n",
    "          ort_values('Difference', ascending= False).reset_index(drop=True))\n",
    "\n",
    "#Wybieramy ostateczne kolumny i gotowe\n",
    "Result = Result[['Id','Title','MaxScore','AcceptedScore','Difference']]\n",
    "\n",
    "czas_Result = timeit.default_timer() - starttime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porównanie zawartości otrzymanych wyników. Nie chcemy, żeby permutacje wierszy miały wpływ podczas porównania, dlatego zresetujemy indeksy i posortujemy je od nowa, według takiego samego porządku. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5_sorted = df5[['Title','MaxScore','AcceptedScore','Difference']]\n",
    "\n",
    "Result_sorted = Result[['Title','MaxScore','AcceptedScore','Difference']]\n",
    "\n",
    "df5_sorted.equals(Result_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otrzymaliśmy $True$, zatem otrzymane wyniki są równoważne. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz porównajmy czas  trwania tych zapytań. \n",
    "\n",
    "Otrzymane czasy mamy poniżej. Widzimy, że czas wykonania za pomoca funkcji * pd.read_sql_query* jest około 2 razy dłuższy, niż drugim sposobem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.37124640000547515, 0.17893570000160253]"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[czas_df5, czas_Result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zamknięcie bazy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podsumowanie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wszystkie 5 zapytań *sql* udało nam się wykonać za pomocą funkcji z biblioteki *Pandas*. W każdym przypadku otrzymane wyniki były równoważne. Porównując czasy działania tych poleceń dużo szybciej zadziałały *zwykłe* funkcjie niż funkcja *pd.read_sql_query*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
